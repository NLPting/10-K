{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import spacy\n",
    "import sys\n",
    "from nltk import sent_tokenize\n",
    "import pandas as pd\n",
    "from flashtext import KeywordProcessor\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "keyword_processor = KeywordProcessor(case_sensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 讀取黑白名單\n",
    "def Load_WhilteBlack(path):\n",
    "    print('Loading.......white&Black list...............')\n",
    "    df_e = pd.read_csv(path)\n",
    "    Ent = []\n",
    "    for ent , label in zip(df_e['Entity'],df_e['islabel']):\n",
    "        if label == 1:\n",
    "            Ent.append(ent)\n",
    "    Ent =[i.replace('LLC','').replace('Ltd','').replace('Inc','').replace(',','').replace('N.V','').replace('Co.','').replace('.','').strip() for i in Ent]\n",
    "    for i in Ent:keyword_processor.add_keyword(i)\n",
    "    return\n",
    "\n",
    "## 找出含有ORG的句子(使用NER+白名單)\n",
    "def Have_NER_sentence(Total_sen ,Main_Company , Year):\n",
    "    Tmp = []\n",
    "    for s in Total_sen:\n",
    "        Ent = keyword_processor.extract_keywords(s)\n",
    "        for e in Ent:\n",
    "            Tmp.append((s , Main_Company,e , Year))\n",
    "    return Tmp\n",
    "## 處理特殊狀況的句子\n",
    "def Filter_Title(sen):\n",
    "    flag = False\n",
    "    doc = nlp(sen)\n",
    "    for token in doc:\n",
    "        if token.pos_=='VERB':\n",
    "            flag = True\n",
    "    return flag\n",
    "\n",
    "## 前處理(過濾表格、圖、標題)\n",
    "def Deal_html_return_sen(html_list):\n",
    "    ## NLTK句子切割\n",
    "    def nltk_sentence_token(Content):\n",
    "        Sen= []\n",
    "        sen_token = sent_tokenize(Content)\n",
    "        for sen in sen_token:\n",
    "            if len(sen.split(' '))>=5 and Filter_Title(sen):\n",
    "                Sen.append(sen)\n",
    "        return Sen\n",
    "    ## 處理特殊狀況的句子\n",
    "    def Filter_Title(sen):\n",
    "        flag = False\n",
    "        doc = nlp(sen)\n",
    "        for token in doc:\n",
    "            if token.pos_=='VERB':\n",
    "                flag = True\n",
    "        return flag\n",
    "    Sen = []\n",
    "    for path_html in html_list:\n",
    "        file = open(path_html , 'r')\n",
    "        soup = BeautifulSoup(file , 'html.parser')\n",
    "        file.close()\n",
    "        tmpp = soup.find_all('p')\n",
    "        After_filter_title_sen = [i.text.strip() for i in tmpp if i.text and len(i.text.split(' '))>=6 and Filter_Title(i.text)]\n",
    "        Content = ' '.join(After_filter_title_sen)\n",
    "        Sen+=nltk_sentence_token(Content)\n",
    "    return Sen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_n_company(i):\n",
    "    years = ['2012','2013','2014','2015','2016','2017']\n",
    "    company_list = glob.glob('xxxx/*/')[:i]\n",
    "    #print(company_list)\n",
    "    Company_sen = []\n",
    "    Company_ent = []\n",
    "    with open('test.sentence.csv','a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([('Sentence','Main','Secondary','Time','Label')])\n",
    "    for i in company_list:\n",
    "        for year in years:\n",
    "            html_list = glob.glob(i+'html/'+year+'*.html')\n",
    "            Main_Company = html_list[0].split('/')[1]\n",
    "            Year = html_list[0].split('/')[-1].split('-')[0].replace('.html','')\n",
    "            #print(Main_Company)\n",
    "            #print(Year)\n",
    "            #print(html_list)\n",
    "            Company_sen = Deal_html_return_sen(html_list)\n",
    "            Result = Have_NER_sentence(Company_sen,Main_Company,Year)\n",
    "            with open('test.sentence.csv','a') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxxx/AMD/']\n",
      "AMD\n",
      "2012\n",
      "['xxxx/AMD/html/2012-2.html', 'xxxx/AMD/html/2012-1.html']\n",
      "AMD\n",
      "2013\n",
      "['xxxx/AMD/html/2013-2.html', 'xxxx/AMD/html/2013-1.html']\n",
      "AMD\n",
      "2014\n",
      "['xxxx/AMD/html/2014-2.html', 'xxxx/AMD/html/2014-1.html']\n",
      "AMD\n",
      "2015\n",
      "['xxxx/AMD/html/2015-1.html', 'xxxx/AMD/html/2015-2.html']\n",
      "AMD\n",
      "2016\n",
      "['xxxx/AMD/html/2016-1.html', 'xxxx/AMD/html/2016-2.html']\n",
      "AMD\n",
      "2017\n",
      "['xxxx/AMD/html/2017-1.html', 'xxxx/AMD/html/2017-2.html']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3022a7267d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchoose_n_company\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-4263b7b118eb>\u001b[0m in \u001b[0;36mchoose_n_company\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mCompany_sen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeal_html_return_sen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHave_NER_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCompany_sen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMain_Company\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.sentence.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-18fee96bc31a>\u001b[0m in \u001b[0;36mDeal_html_return_sen\u001b[0;34m(html_list)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mAfter_filter_title_sen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmpp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m6\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mFilter_Title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mContent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAfter_filter_title_sen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mSen\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mnltk_sentence_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mContent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-18fee96bc31a>\u001b[0m in \u001b[0;36mnltk_sentence_token\u001b[0;34m(Content)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0msen_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mContent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msen_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mFilter_Title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mSen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-18fee96bc31a>\u001b[0m in \u001b[0;36mFilter_Title\u001b[0;34m(sen)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mFilter_Title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'VERB'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__call__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.parse_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Load_WhilteBlack('flair.csv')\n",
    "choose_n_company(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.sentence.csv','w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    ['Sentence','Main','Secondary','Time','Label']:\n",
    "    writer.writerow([['Sentence','Main','Secondary','Time','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
